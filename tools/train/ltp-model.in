#!/usr/bin/env python

# a python wrapper for training process in ltp
#
# author: Yijia Liu
# date: 2013-3-23
# copyright: HIT-SCIR<ir.hit.edu.cn>

import sys
import os
import hashlib
import time
import shutil
import traceback
import json
import threading
import subprocess

# py-corpusproc is thirdparty modules of text processing in
# python, import py-corpusproc modules
try:
    # module has been installed
    from corpusproc.io import PlainReader, SegmentReader, PostagReader
    from corpusproc.io import PlainWriter, SegmentWriter, PostagWriter
except:
    # module not installed
    bin_path = os.path.realpath(__file__)
    bin_dir  = os.path.split(bin_path)[0]
    root_dir = os.path.join(bin_dir, "corpusproc")
    sys.path.append(root_dir)

    from corpusproc.io import PlainReader, SegmentReader, PostagReader
    from corpusproc.io import PlainWriter, SegmentWriter, PostagWriter

from optparse import OptionParser, make_option

# attention here, cmake should replace this
ROOT            = "${TOOLS_DIR}/train/"
CRFLEARN_EXE    = "${TOOLS_DIR}/train/crf_learn"
MAXENT_EXE      = "${TOOLS_DIR}/train/maxent"
SRLEXT_EXE      = "${TOOLS_DIR}/train/SRLExtract"
SRLGET_EXE      = "${TOOLS_DIR}/train/SRLGetInstance"
GPARSER_EXE     = "${TOOLS_DIR}/train/gparser"
CONF_DIR        = "${TOOLS_DIR}/train/assets"
BUILD_DIR       = "${TOOLS_DIR}/train/build"
MODEL_DIR       = "${MODEL_DIR}-sandbox"

try:
    fp=open("ltp-model.json", "r")
    VALID_TARGETS=json.load(fp, encoding="utf8")
    fp.close()
except:
    # if the json file is not find, build with default value
    trace =  "TRACE: Failed to load ltp-model.json, "
    trace += "an empty is built."
    print >> sys.stderr, trace
    VALID_TARGETS={
            "ws": {
                "ClassName":    "Wordseg",
                "BuildSubdir":  "crfws_data",
                "ConfigModels": {
                    "pku_all.model": None,},
                "ConfigFiles":  {},
                },
            "srl": {
                "ClassName":    "SRL",
                "BuildSubdir":  "srl_data",
                "ConfigModels": {
                    "binary_model": None,},
                "ConfigFiles":  {
                    "Chinese.xml":  os.path.join(CONF_DIR, "Chinese.xml"),
                    "conll2009-arg.conf":   os.path.join(CONF_DIR, "conll2009-arg.conf"),
                    },
                },
            "dp": {
                "ClassName":    "DP",
                "BuildSubdir":  "gparser_data",
                "ConfigModels":  {
                    "parameter..ircdt10k.model": None,
                    "alphabet.ircdt10k.model": None,},
                "ConfigFiles":  {
                    "config.ircdt_10k.txt": os.path.join(CONF_DIR, "gparser.test.conf"),
                    },
                }}

# hash file with MD5, return MD5 code of this file
#
#   @param  fp          the file handle
#   @param  block_size  size of block each read
def MD5(fp, block_size = 2**20):
    md5 = hashlib.md5()
    while True:
        data = fp.read(block_size)
        if not data:
            break
        md5.update(data)
    return md5.hexdigest()

class TimeoutCommand(threading.Thread):
    def __init__(self, args, timeout = None):
        threading.Thread.__init__(self)
        self.args = args
        self.timeout = timeout

    def run(self):
        self.p = subprocess.Popen(self.args)
        self.p.wait()

    def exe(self):
        self.start()
        self.join(self.timeout)

        if self.is_alive():
            self.p.terminate()
            self.join()

class Trainer(object):
    """
    basic class for trainer
    """
    def __init__(self):
        pass

    # method for executing training process
    # this method should be overwrite
    def train(self):
        pass

    # method for showing help
    # this method should be overwrite
    def help(self):
        pass

    def _check_and_build(self, data_id):
        if not os.path.isdir(BUILD_DIR):
            os.mkdir(BUILD_DIR)

        data_root=os.path.join(BUILD_DIR, data_id)
        if not os.path.isdir(data_root):
            os.mkdir(data_root)
        return data_root


class WordsegTrainer(Trainer):
    """
    word segment trainer, an example of the training schema is

    ./extract features
    ./crfpp
    """
    def __init__(self):
        self.parser = self._opt_parser()
        self.opts, self.args = self.parser.parse_args()
        try:
            self.opts, self.args = self.parser.parse_args()
        except:
            raise Exception("Parsing option error")

    def train(self):
        if self.opts.trainfile is None:
            self.help()
            raise Exception("Import file is not set.")

        # make directory
        os.chdir(ROOT)
        data_root = self._check_and_build( VALID_TARGETS["ws"]["BuildSubdir"] )

        try:
            fp=open(self.opts.trainfile, "r")
        except:
            err = "ERROR: Failed to open file %s" % self.opts.trainfile
            print >> sys.stderr, err
            raise Exception(err)

        # check if exist in build
        # hash the file with md5 and encode the hash code into filename
        # the rest is too check the md5 value
        md5_code = MD5(fp)[:10]
        model_name = "%s.ws.model" % md5_code
        model_path = os.path.join(data_root, model_name)

        # model has been trained
        train_name = "%s.ws.train" % md5_code
        train_path = os.path.join(data_root, train_name)

        if os.path.isfile(model_path):
            trace = "TRACE: This file has been trained"
            print >> sys.stderr, trace
            VALID_TARGETS["ws"]["ConfigModels"]["pku_all.model"]=model_path
            return

        try:
            fpo=open(train_path, "w")
        except:
            err = "ERROR: Failed to open file %s" % train_file
            print >> sys.stderr, err
            raise Exception(err)

        # read corpus and generate train file
        reader = SegmentReader(fp)
        reader.seek(0)

        inst = reader.get()
        while inst is not None:
            for word in inst.forms:
                chars = word.decode(self.opts.encoding)

                for i in xrange(len(chars)):
                    if i == 0:
                        print >> fpo, "%s\t%s" % (chars[i].encode(self.opts.encoding), "B")
                    else:
                        print >> fpo, "%s\t%s" % (chars[i].encode(self.opts.encoding), "I")

            print >> fpo
            inst = reader.get()

        fp.close(); fpo.close()

        args_list = [CRFLEARN_EXE]

        i = 3
        while i < len(sys.argv):
            if (sys.argv[i].startswith("--encoding=") or 
                    sys.argv[i].startswith("--train=")):
                i += 1
                continue

            if sys.argv[i] == "-i":
                i += 2
                continue

            args_list.append(sys.argv[i])
            i += 1

        args_list.append( os.path.join(CONF_DIR, "crfpp.template") )
        args_list.append( train_path )
        args_list.append( model_path )
        TimeoutCommand( args_list ).exe()

        # model is built, set the settings section
        VALID_TARGETS["ws"]["ConfigModels"]["pku_all.model"]=model_path

    def help(self):
        self.parser.print_help()

    # initialize option parser for word segment trainer
    def _opt_parser(self):
        usage =     "LTP (Language Technology Platform) Training Wrapper: Chinese Word Segmentation Trainer\n"
        usage +=    "\n"
        usage +=    "Author: Yijia Liu, Copyright (c) 2013 HIT-SCIR\n"
        usage +=    "\n"
        usage +=    "USAGE: ./ltp-model build ws [OPTIONS]"
        opt_list = [
                make_option("-f", "--freq",
                    type="int", default=3, dest="freq",
                    help="use features that occuer no less than INT(default 3)"),
                make_option("-m", "--maxiter",
                    type="int", default=10000, dest="maxiter",
                    help="set INT for max iterations in LBFGS routine(default 10k)"),
                make_option("-c", "--cost",
                    type="float", default=1.0, dest="cost",
                    help="set FLOAT for cost parameter(default 1.0)"),
                make_option("-e", "--eta",
                    type="float", default=0.0001, dest="eta",
                    help="set FLOAT for termination criterion(default 0.0001)"),
                make_option("-C", "--convert",
                    action="store_true", dest="convert",
                    help="convert text model to binary model"),
                make_option("--textmodel",
                    action="store_true", dest="textmodel",
                    help="build also text model file for debugging"),
                make_option("-a", "--algorithm",
                    dest="algorithm",
                    help="select training algorithm(CRF|MIRA)"),
                make_option("-p", "--thread",
                    type="int", dest="thread", default=1,
                    help="number of threads(default 1)"),
                make_option("-H", "--shrinking-size",
                    type="int", dest="shrinking", default=20,
                    help="set INT for number of iterations variable needs to "
                    "be optimal before considered for shrinking. (default 20)"),
                make_option("-i", "--train",
                    dest="trainfile",
                    help="set training corpus path"),
                make_option("--encoding",
                    dest="encoding", default="utf8",
                    help="set corpus encoding")]

        opt_parser = OptionParser(usage=usage, option_list=opt_list)

        return opt_parser


class POSTagTrainer(Trainer):
    def __init__(self):
        pass

    def train(self):
        pass

    def help(self):
        pass

    def _opt_parser(self):
        usage = ""


class DPTrainer(Trainer):
    def __init__(self):
        self.parser = self._opt_parser()
        try:
            self.opts, self.args = self.parser.parse_args()
        except:
            raise Exception("Parsing arguments error")

        if self.opts.configfile == None:
            self.help()
            raise Exception("Configure file is must.")

    def train(self):
        os.chdir(ROOT)
        data_root = self._check_and_build( VALID_TARGETS["dp"]["BuildSubdir"] )

        try:
            fp=open(self.opts.configfile, "r")
        except:
            err = "ERROR: Failed to open config file %s" % self.opts.configfile
            print >> sys.stderr, err
            raise Exception(err)

        trainfile = ""
        for line in fp:
            if line.startswith("train-file"):
                trainfile=line.strip().split(":", 1)[1]
        fp.close()

        try:
            fp=open(trainfile, "r")
        except:
            err = "ERROR: Failed to open config file %s" % trainfile
            print >> sys.stderr, err

        md5_code = MD5(fp)[:10]
        model_alpha_path = os.path.join(data_root, "%s.alphabet.gparser.model" % md5_code)
        model_param_path = os.path.join(data_root, "%s.parameter..gparser.model" % md5_code)

        if os.path.isfile(model_alpha_path) and os.path.isfile(model_param_path):
            trace = "TRACE: model has be trained"
            print >> sys.stderr, trace
            VALID_TARGETS["dp"]["ConfigModels"]["alphabet.ircdt10k.model"] = model_alpha_path
            VALID_TARGETS["dp"]["ConfigModels"]["parameter..ircdt10k.model"] = model_param_path
            return 

        args_list = [GPARSER_EXE,
                self.opts.configfile]

        TimeoutCommand( args_list ).exe()

        shutil.move(os.path.join(ROOT, "alphabet.ltp.gparser.model"),
                model_alpha_path)
        shutil.move(os.path.join(ROOT, "parameter..ltp.gparser.model"),
                model_param_path)

        VALID_TARGETS["dp"]["ConfigModels"]["alphabet.ircdt10k.model"] = model_alpha_path
        VALID_TARGETS["dp"]["ConfigModels"]["parameter..ircdt10k.model"] = model_param_path
 
        
    def help(self):
        self.parser.print_help()

    def _opt_parser(self):
        usage =     "LTP (Language Technology Platform) Training Wrapper: Dependency Parser Trainer\n"
        usage +=    "\n"
        usage +=    "Author: Yijia Liu, Copyright (c) 2013 HIT-SCIR\n"
        usage +=    "\n"
        usage +=    "USAGE: ./ltp-model build dp [OPTIONS]"

        opt_list = [
                make_option("-c", "--config",
                    dest="configfile",
                    default=os.path.join(CONF_DIR, "gparser.conf"),
                    help="set configure file"),
                make_option("--encoding",
                    dest="encoding", default="utf8",
                    help="set corpus encoding")]

        opt_parser = OptionParser(usage=usage, option_list=opt_list)

        return opt_parser

class SRLTrainer(Trainer):
    """ Senentic Role Labeling training wrapper, and example of SRL
    training process is shown below.

    ./SRLExtractor ./conf/Chinese.xml <trainfile> tmp_dir
    ./SRLGetInstance ./

    """
    def __init__(self):
        self.parser = self._opt_parser()
        try:
            self.opts, self.args = self.parser.parse_args()
        except:
            raise Exception("Parsing arguments error")

        if self.opts.trainfile == None:
            self.help()
            raise Exception("Training file is must.")

    def train(self):
        os.chdir(ROOT)
        data_root = self._check_and_build( VALID_TARGETS["srl"]["BuildSubdir"] )
        tmp_root  = os.path.join(data_root, "tmp")

        if not os.path.isdir(tmp_root):
            os.mkdir(tmp_root)

        try:
            fp=open(self.opts.trainfile, "r")
        except:
            err = "ERROR: Failed to open file %s" % self.opts.trainfile
            print >> sys.stderr, err
            raise Exception(err)

        md5_code = MD5(fp)[:10]
        model_name = "%s.srl.model" % md5_code
        model_path = os.path.join(data_root, model_name)

        # model has been trained
        train_name = "%s.srl.train" % md5_code
        train_path = os.path.join(data_root, train_name)

        if os.path.isfile(model_path):
            trace = "TRACE: This file has been trained"
            print >> sys.stderr, trace
            VALID_TARGETS["srl"]["ConfigModels"]["binary_model"]=model_path
            return

        # srl extract structure
        args_list = [SRLEXT_EXE,
                os.path.join(CONF_DIR, "Chinese.xml"),
                self.opts.trainfile,
                tmp_root]
        TimeoutCommand(args_list).exe()

        # srl get instance
        args_list = [SRLGET_EXE,
                os.path.join(CONF_DIR, "Chinese.xml"),
                tmp_root,
                os.path.join(CONF_DIR, "conll2009-arg.conf"),
                train_path ]
        TimeoutCommand(args_list).exe()

        # maxent toolkit
        args_list = [MAXENT_EXE, 
                "-g", "2",
                "-i", "100",
                "-v",
                "-b",
                "-m", model_path] 
        args_list.append( train_path + ".verb" )
        TimeoutCommand(args_list).exe()
        VALID_TARGETS["srl"]["ConfigModels"]["binary_model"]=model_path

    def help(self):
        self.parser.print_help()

    def _opt_parser(self):
        usage =     "LTP (Language Technology Platform) Training Wrapper: Semantic Role Labeling Trainer\n"
        usage +=    "\n"
        usage +=    "Author: Yijia Liu, Copyright (c) 2013 HIT-SCIR\n"
        usage +=    "\n"
        usage +=    "USAGE: ./ltp-model build srl [OPTIONS]"
        opt_list = [
                make_option("-i", "--train",
                    dest="trainfile",
                    help="set training corpus path"),
                make_option("--encoding",
                    dest="encoding", default="utf8",
                    help="set corpus encoding")]

        opt_parser = OptionParser(usage=usage, option_list=opt_list)

        return opt_parser

def build(target):
    # a meta function for create class
    def createObject(className):
        cls = globals()[className]

        if isinstance(cls, type):
            return cls()
        else:
            raise Exception("No such class")

    # create a trainer
    try:
        trainer = createObject(VALID_TARGETS[target]["ClassName"]+"Trainer")
    except:
        err = "ERROR: failed to create trainer"
        print >> sys.stderr, err
        traceback.print_exc(sys.stderr)
        return

    # execute training process
    try:
        trainer.train()
        print >> sys.stderr, "TRACE: training is done."
    except:
        err = "ERROR: training failed"
        print >> sys.stderr, err
        print >> sys.stderr
        traceback.print_exc(sys.stderr)

def install():
    os.chdir(ROOT)

    if not os.path.isdir(MODEL_DIR):
        os.mkdir(MODEL_DIR)

    for target in VALID_TARGETS:

        output_dir = os.path.join(MODEL_DIR, VALID_TARGETS[target]["BuildSubdir"])
        if not os.path.isdir(output_dir):
            os.mkdir(output_dir)

        for k, v in VALID_TARGETS[target]["ConfigModels"].iteritems():
            output_file = os.path.join(output_dir, k)
            shutil.copyfile(v, output_file)
            trace = "TRACE: installing\n -- %s to\n -- %s\n" % (v, output_file)
            print >> sys.stderr, trace

        for k, v in VALID_TARGETS[target]["ConfigFiles"].iteritems():
            output_file = os.path.join(output_dir, k)
            shutil.copyfile(v, output_file)
            trace = "TRACE: installing\n -- %s to\n -- %s\n" % (v, output_file)
            print >> sys.stderr, trace


        #model_files = get_model_files(target)
        #if len(model_files) == 0:
        #    build(target)

        #shutil.copyfile(model_file,
        #        os.path.join(output_dir, VALID_TARGETS[target][2]))

    srl_data_dir = os.path.join(MODEL_DIR, "srl_data")
    shutil.copyfile(os.path.join(CONF_DIR, "Chinese.xml"),
            os.path.join(srl_data_dir, "Chinese.xml"))
    shutil.copyfile(os.path.join(CONF_DIR, "conll2009-arg.conf"),
            os.path.join(srl_data_dir, "conll2009-arg.conf"))


def clean():
    os.chdir(ROOT)

    if os.path.isdir("build"):
        shutil.rmtree("build")

    trace = "TRACE: clean build"
    print >> sys.stderr, trace


def main():
    # specify usage
    usage =     "LTP (Language Technology Platform) Training Wrapper\n"
    usage +=    "Author: Yijia Liu, Copyright (c) 2013 HIT-SCIR"
    usage +=    "\n%s\n"
    usage +=    "USAGE: ./train <COMMAND> [OPTIONS]\n"
    usage +=    "    COMMAND        Command name to specify the training process\n"
    usage +=    "    OPTIONS        Arguments for the command (command-specific)\n"
    usage +=    "\n"
    usage +=    "COMMAND:\n"
    usage +=    "    build [TARGET] Build model specified by [TARGET]\n"
    usage +=    "    install        Install model into ltp\n"
    usage +=    "    clean          Clean the model\n"

    if len(sys.argv) < 2 or (len(sys.argv) == 2 and (sys.argv[1] == "-h" or sys.argv[1] == "--help")):
        print >> sys.stderr, usage % ""
        return

    if sys.argv[1] not in ["build", "install", "clean"]:
        err = "\nERROR: Unknown command [%s]\n" % sys.argv[1]
        print >> sys.stderr, usage % err
        return

    if sys.argv[1] == "build" and (len(sys.argv) < 3 or sys.argv[2] not in VALID_TARGETS):
        err = "\nERROR: Build target should be [ws|pos|srl|dp]\n"
        print >> sys.stderr, usage % err
        return

    if sys.argv[1] == "build":
        build(sys.argv[2])
    elif sys.argv[1] == "install":
        install()
    elif sys.argv[1] == "clean":
        clean()
    else:
        raise Exception("Something must went wrong =(");

if __name__=="__main__":
    main()

    try:
        fpo=open("ltp-model.json", "w")
        print >> fpo, json.dumps(VALID_TARGETS, indent=4)
    except:
        print >> sys.stderr, "Failed to write ltp-model.json"
