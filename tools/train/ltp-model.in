#!/usr/bin/env python

# a python wrapper for training process in ltp
#
# author: Yijia Liu
# date: 2013-3-23
import sys, os
import hashlib
import subprocess
import time
import shutil

# import py-corpusproc modules
try:
    # module has been installed
    from corpusproc.io import PlainReader, SegmentReader, PostagReader
    from corpusproc.io import PlainWriter, SegmentWriter, PostagWriter
except:
    # module not installed
    bin_path = os.path.realpath(__file__)
    bin_dir  = os.path.split(bin_path)[0]
    root_dir = os.path.join(bin_dir, "corpusproc")
    sys.path.append(root_dir)

    from corpusproc.io import PlainReader, SegmentReader, PostagReader
    from corpusproc.io import PlainWriter, SegmentWriter, PostagWriter

from optparse import OptionParser, make_option

VALID_TARGETS = {
        "ws":   ("Wordseg", "crfws_data",   "pku_all.model"),
        #"pos":  ("POSTag", "svmtagger_data")
        "srl":  ("SRL",     "srl_data",     "binary_model"),}

# attention here, cmake should replace this
ROOT            = "${TOOLS_DIR}/train/"
CRFLEARN_EXE    = "${TOOLS_DIR}/train/crf_learn"
MAXENT_EXE      = "${TOOLS_DIR}/train/maxent"
SRLEXT_EXE      = "${TOOLS_DIR}/train/SRLExtract"
SRLGET_EXE      = "${TOOLS_DIR}/train/SRLGetInstance"
CONF_DIR        = "${TOOLS_DIR}/train/assets"

MODEL_DIR       = "${MODEL_DIR}"

def MD5(fp, block_size = 2**20):
    md5 = hashlib.md5()
    while True:
        data = fp.read(block_size)
        if not data:
            break
        md5.update(data)
    return md5.hexdigest()


import threading

class TimeoutCommand(threading.Thread):
    def __init__(self, args, timeout = None):
        threading.Thread.__init__(self)
        self.args = args
        self.timeout = timeout

    def run(self):
        self.p = subprocess.Popen(self.args)
        self.p.wait()

    def exe(self):
        self.start()
        self.join(self.timeout)

        if self.is_alive():
            self.p.terminate()
            self.join()

# basic class for trainer
class Trainer(object):

    def __init__(self):
        pass

    # method for executing training process
    # this method should be overwrite
    def train(self):
        pass

    # method for showing help
    # this method should be overwrite
    def help(self):
        pass

    def _check_and_build(self, data_id):
        if not os.path.isdir("build"):
            os.mkdir("build")

        data_root=os.path.join("build", data_id)

        if not os.path.isdir(data_root):
            os.mkdir(data_root)

        return data_root


# word segment trainer
class WordsegTrainer(Trainer):

    def __init__(self):
        self.parser = self._opt_parser()
        try:
            self.opts, self.args = self.parser.parse_args()
        except:
            raise Exception("Parsing option error")

        if self.opts.trainfile is None:
            self.help()
            raise Exception("Import file is not set.")

    def train(self):
        # make directory
        os.chdir(ROOT)
        data_root = self._check_and_build( VALID_TARGETS["ws"][1] )

        try:
            fp=open(self.opts.trainfile, "r")
        except:
            err = "ERROR: Failed to open file %s" % self.opts.trainfile
            print >> sys.stderr, err
            raise Exception(err)

        # check if exist in build
        # hash the file with md5 and encode the hash code into filename
        # the rest is too check the md5 value
        md5_code = MD5(fp)[:10]
        model_name = "ws.%s.model" % md5_code
        model_path = os.path.join(data_root, model_name)

        # model has been trained
        train_name = "ws.%s.train" % md5_code
        train_path = os.path.join(data_root, train_name)

        if os.path.isfile(model_path):
            trace = "TRACE: This file has been trained"
            print >> sys.stderr, trace
            return

        try:
            fpo=open(train_path, "w")
        except:
            err = "ERROR: Failed to open file %s" % train_file
            print >> sys.stderr, err
            raise Exception(err)

        # read corpus and generate train file
        reader = SegmentReader(fp)
        reader.seek(0)

        inst = reader.get()
        while inst is not None:
            for word in inst.forms:
                chars = word.decode(self.opts.encoding)

                for i in xrange(len(chars)):
                    if i == 0:
                        print >> fpo, "%s\t%s" % (chars[i].encode(self.opts.encoding), "B")
                    else:
                        print >> fpo, "%s\t%s" % (chars[i].encode(self.opts.encoding), "I")

            print >> fpo
            inst = reader.get()

        fp.close()
        fpo.close()

        args_list = [CRFLEARN_EXE]

        i = 3
        while i < len(sys.argv):
            if (sys.argv[i].startswith("--encoding=") or 
                    sys.argv[i].startswith("--train=")):
                i += 1
                continue

            if sys.argv[i] == "-i":
                i += 2
                continue

            args_list.append(sys.argv[i])
            i += 1

        args_list.append( os.path.join(CONF_DIR, "crfpp.template") )
        args_list.append( train_path )
        args_list.append( model_path )

        TimeoutCommand( args_list ).exe()

    def help(self):
        self.parser.print_help()

    # initialize option parser for word segment trainer
    def _opt_parser(self):
        usage =     "LTP (Language Technology Platform) Training Wrapper: Chinese Word Segmentation Trainer\n"
        usage +=    "\n"
        usage +=    "Author: Yijia Liu, Copyright (c) 2013 HIT-SCIR\n"
        usage +=    "\n"
        usage +=    "USAGE: ./ltp-model build ws [OPTIONS]"
        opt_list = [
                make_option("-f", "--freq",
                    type="int", default=3, dest="freq",
                    help="use features that occuer no less than INT(default 3)"),
                make_option("-m", "--maxiter",
                    type="int", default=10000, dest="maxiter",
                    help="set INT for max iterations in LBFGS routine(default 10k)"),
                make_option("-c", "--cost",
                    type="float", default=1.0, dest="cost",
                    help="set FLOAT for cost parameter(default 1.0)"),
                make_option("-e", "--eta",
                    type="float", default=0.0001, dest="eta",
                    help="set FLOAT for termination criterion(default 0.0001)"),
                make_option("-C", "--convert",
                    action="store_true", dest="convert",
                    help="convert text model to binary model"),
                make_option("--textmodel",
                    action="store_true", dest="textmodel",
                    help="build also text model file for debugging"),
                make_option("-a", "--algorithm",
                    dest="algorithm",
                    help="select training algorithm(CRF|MIRA)"),
                make_option("-p", "--thread",
                    type="int", dest="thread", default=1,
                    help="number of threads(default 1)"),
                make_option("-H", "--shrinking-size",
                    type="int", dest="shrinking", default=20,
                    help="set INT for number of iterations variable needs to "
                    "be optimal before considered for shrinking. (default 20)"),
                make_option("-i", "--train",
                    dest="trainfile",
                    help="set training corpus path"),
                make_option("--encoding",
                    dest="encoding", default="utf8",
                    help="set corpus encoding")]

        opt_parser = OptionParser(usage=usage, option_list=opt_list)

        return opt_parser


class POSTagTrainer(Trainer):
    def __init__(self):
        pass

    def train(self):
        pass

    def help(self):
        pass

    def _opt_parser(self):
        usage = ""


class SRLTrainer(Trainer):

    def __init__(self):
        self.parser = self._opt_parser()
        try:
            self.opts, self.args = self.parser.parse_args()
        except:
            raise Exception("Parsing arguments error")

        if self.opts.trainfile == None:
            self.help()
            raise Exception("Corpus, template and configure file is must")

    def train(self):
        os.chdir(ROOT)
        data_root = self._check_and_build( VALID_TARGETS["srl"][1] )
        tmp_root  = os.path.join(data_root, "tmp")

        if not os.path.isdir(tmp_root):
            os.mkdir(tmp_root)

        try:
            fp=open(self.opts.trainfile, "r")
        except:
            err = "ERROR: Failed to open file %s" % self.opts.trainfile
            print >> sys.stderr, err
            raise Exception(err)

        md5_code = MD5(fp)[:10]
        model_name = "srl.%s.model" % md5_code
        model_path = os.path.join(data_root, model_name)

        # model has been trained
        train_name = "srl.%s.train" % md5_code
        train_path = os.path.join(data_root, train_name)

        if os.path.isfile(model_path):
            trace = "TRACE: This file has been trained"
            print >> sys.stderr, trace
            return

        # srl extract
        args_list = [SRLEXT_EXE]
        args_list.append( os.path.join(CONF_DIR, "Chinese.xml") )
        args_list.append( self.opts.trainfile )
        args_list.append( tmp_root )

        TimeoutCommand( args_list ).exe()

        args_list = [SRLGET_EXE]
        args_list.append( os.path.join(CONF_DIR, "Chinese.xml") )
        args_list.append( tmp_root )
        args_list.append( os.path.join(CONF_DIR, "conll2009-arg.conf") )
        args_list.append( train_path )

        TimeoutCommand( args_list ).exe()

        args_list = [MAXENT_EXE, 
                "-g", "2",
                "-i", "100",
                "-v",
                "-b",
                "-m", train_path + ".verb.model"]
        args_list.append( train_path + ".verb" )

        TimeoutCommand( args_list ).exe()

    def help(self):
        self.parser.print_help()

    def _opt_parser(self):
        usage =     "LTP (Language Technology Platform) Training Wrapper: Semantic Role Labeling Trainer\n"
        usage +=    "\n"
        usage +=    "Author: Yijia Liu, Copyright (c) 2013 HIT-SCIR\n"
        usage +=    "\n"
        usage +=    "USAGE: ./ltp-model build srl [OPTIONS]"
        opt_list = [
                make_option("-i", "--train",
                    dest="trainfile",
                    help="set training corpus path"),
                make_option("--encoding",
                    dest="encoding", default="utf8",
                    help="set corpus encoding")]

        opt_parser = OptionParser(usage=usage, option_list=opt_list)

        return opt_parser

def build(target):
    # a meta function for create class
    def createObject(className):
        cls = globals()[className]

        if isinstance(cls, type):
            return cls()
        else:
            raise Exception("No such class")

    # create a trainer
    try:
        trainer = createObject(VALID_TARGETS[target][0] + "Trainer")
    except:
        return

    # execute training process
    try:
        trainer.train()
        print >> sys.stderr, "training is done."
    except:
        err = "training failed"
        print >> sys.stderr, err

def install():
    os.chdir(ROOT)

    def get_model_files(target):
        target_dir = os.path.join("build", VALID_TARGETS[target][1])
        if not os.path.isdir(target_dir):
            return []

        files = [f for f in os.listdir(target_dir)
                if f.startswith(target + ".") and f.endswith(".model")]

        return files

    if not os.path.isdir(MODEL_DIR):
        os.mkdir(MODEL_DIR)

    for target in VALID_TARGETS:

        model_files = get_model_files(target)
        if len(model_files) == 0:
            build(target)

        output_dir = os.path.join(MODEL_DIR, VALID_TARGETS[target][1])
        if not os.path.isdir(output_dir):
            os.mkdir(output_dir)

        model_file = os.path.join("build", VALID_TARGETS[target][1])
        model_file = os.path.join(model_file, model_files[0])
        shutil.copyfile(model_file,
                os.path.join(output_dir, VALID_TARGETS[target][2]))

    srl_data_dir = os.path.join(MODEL_DIR, "srl_data")
    shutil.copyfile(os.path.join(CONF_DIR, "Chinese.xml"),
            os.path.join(srl_data_dir, "Chinese.xml"))
    shutil.copyfile(os.path.join(CONF_DIR, "conll2009-arg.conf"),
            os.path.join(srl_data_dir, "conll2009-arg.conf"))


def clean():
    os.chdir(ROOT)

    if os.path.isdir("build"):
        shutil.rmtree("build")

    trace = "TRACE: clean build"
    print >> sys.stderr, trace


def main():
    # specify usage
    usage =     "LTP (Language Technology Platform) Training Wrapper\n"
    usage +=    "Author: Yijia Liu, Copyright (c) 2013 HIT-SCIR"
    usage +=    "\n%s\n"
    usage +=    "USAGE: ./train <COMMAND> [OPTIONS]\n"
    usage +=    "    COMMAND        Command name to specify the training process\n"
    usage +=    "    OPTIONS        Arguments for the command (command-specific)\n"
    usage +=    "\n"
    usage +=    "COMMAND:\n"
    usage +=    "    build [TARGET] Build model specified by [TARGET]\n"
    usage +=    "    install        Install model into ltp\n"
    usage +=    "    clean          Clean the model\n"

    if len(sys.argv) < 2 or (len(sys.argv) == 2 and (sys.argv[1] == "-h" or sys.argv[1] == "--help")):
        print >> sys.stderr, usage % ""
        return

    if sys.argv[1] not in ["build", "install", "clean"]:
        err = "\nERROR: Unknown command [%s]\n" % sys.argv[1]
        print >> sys.stderr, usage % err
        return

    if sys.argv[1] == "build" and (len(sys.argv) < 3 or sys.argv[2] not in VALID_TARGETS):
        err = "\nERROR: Build target should be [ws|pos|srl]\n"
        print >> sys.stderr, usage % err
        return

    if sys.argv[1] == "build":
        build(sys.argv[2])

    elif sys.argv[1] == "install":
        install()

    elif sys.argv[1] == "clean":
        clean()

    else:
        raise Exception("Something must went wrong =(");

if __name__=="__main__":
    main()
